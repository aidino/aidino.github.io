{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example: Prompt+Model+OutputParser\n",
    "\n",
    "The most fundamental and commonly used case involves linking a prompt template with a model. To illustrate how this works, let us create a chain that asks for the capital cities of various countries.\n",
    "\n",
    "**Environtment**\n",
    "\n",
    "```bash\n",
    "pip install langsmith langchain langchain_openai langchain_community\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True, dotenv_path='../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Prompt Templates\n",
    "\n",
    "**`PromptTemplate`**\n",
    "\n",
    "-   `PromptTemplate` được sử dụng để tạo ra một chuỗi prompt hoàn chỉnh bằng cách kết hợp các biến đầu vào (input variables) từ người dùng.\n",
    "-   Cách sử dụng:\n",
    "    -   `template`: Một chuỗi template là một định dạng được định sẵn, nơi dấu ngoặc nhọn '{}' được sử dụng để đại diện cho các biến.\n",
    "    -   `input_variables`: Tên của các biến cần được chèn vào trong dấu ngoặc nhọn được định nghĩa dưới dạng một danh sách.\n",
    "\n",
    "**`input_variables`**\n",
    "\n",
    "-   `input_variables` là một danh sách định nghĩa tên của các biến được sử dụng trong `PromptTemplate`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='Thành phố của {country} là gì?')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"Thành phố của {country} là gì?\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thành phố của Việt Nam là gì?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(country=\"Việt Nam\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Creation\n",
    "\n",
    "### LCEL (LangChain Expression Language)\n",
    "\n",
    "Ở đây, chúng ta sử dụng LCEL (LangChain Expression Language) để kết hợp các thành phần khác nhau thành một chuỗi (chain) duy nhất.\n",
    "\n",
    "![lcel.png](https://raw.githubusercontent.com/aidino/LangChain-OpenTutorial/683d91eb3fd1028345ee8e5b80660b3b0fcc6b96/01-Basic/assets/02-langchain-expression-language.png)\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "Đúng vậy, ký hiệu `|` hoạt động tương tự như toán tử pipe trong Unix, liên kết các thành phần khác nhau và truyền đầu ra của thành phần này làm đầu vào cho thành phần tiếp theo.\n",
    "\n",
    "Trong chuỗi này, đầu vào của người dùng được chuyển đến template prompt, và đầu ra từ template prompt sau đó được chuyển tiếp đến model. Bằng cách xem xét từng thành phần riêng lẻ, bạn có thể hiểu những gì xảy ra ở mỗi bước.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Thành phố của Việt Nam là Hà Nội.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 17, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ab45cd70-5709-4358-8c34-d3e814fb255c-0', usage_metadata={'input_tokens': 17, 'output_tokens': 17, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Vietnam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Thủ đô của Nga là Moscow.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 18, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-04df5cfa-6d30-4559-9485-31ea13bc679b-0', usage_metadata={'input_tokens': 18, 'output_tokens': 11, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Rusia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of outputting a streaming response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thủ đô của Việt Nam là Hà Nội."
     ]
    }
   ],
   "source": [
    "answer = chain.stream(\"Vietnam\")\n",
    "\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)\n",
    "    \n",
    "#  flush=True đảm bảo rằng đầu ra được hiển thị ngay lập tức, \n",
    "# điều này rất hữu ích trong các tình huống yêu cầu phản hồi theo thời gian thực hoặc hiển thị tiến trình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "\n",
    "Một **Output Parser** là một công cụ được thiết kế để chuyển đổi hoặc xử lý các phản hồi từ mô hình AI thành một định dạng cụ thể. Vì đầu ra của mô hình thường được cung cấp dưới dạng văn bản tự do (free-form text), **Output Parser** là cần thiết để chuyển đổi nó thành một định dạng có cấu trúc hoặc trích xuất dữ liệu cần thiết.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = (\n",
    "    StrOutputParser()\n",
    ") # Directly returns the model's response as a string without modification.\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Explain about {topic}\")\n",
    "chain = prompt_template | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data. \\n\\nIn machine learning, computers are trained to recognize patterns in data and make decisions or predictions without being explicitly programmed to do so. This is achieved through the use of algorithms that analyze and learn from large amounts of data, known as training data. \\n\\nThere are several types of machine learning algorithms, including supervised learning, unsupervised learning, and reinforcement learning. In supervised learning, the algorithm is trained on labeled data, where the correct output is provided for each input. In unsupervised learning, the algorithm is trained on unlabeled data and must find patterns or relationships within the data on its own. In reinforcement learning, the algorithm learns through trial and error, receiving feedback in the form of rewards or penalties for its actions.\\n\\nMachine learning is used in a wide range of applications, including image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles. It has the potential to revolutionize industries such as healthcare, finance, and manufacturing by enabling more efficient and accurate decision-making processes.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('Machine Learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data. \\n\\nIn machine learning, computers are trained to recognize patterns in data and make decisions or predictions without being explicitly programmed to do so. This is achieved through the use of algorithms that analyze and learn from large amounts of data, known as training data. \\n\\nThere are several types of machine learning algorithms, including supervised learning, unsupervised learning, and reinforcement learning. In supervised learning, the algorithm is trained on labeled data, where the correct output is provided for each input. In unsupervised learning, the algorithm is trained on unlabeled data and must find patterns or relationships within the data on its own. Reinforcement learning involves training an algorithm to make decisions based on feedback from its environment. \\n\\nMachine learning is used in a wide range of applications, including image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles. It has the potential to revolutionize many industries by enabling computers to perform tasks that were previously thought to be too complex for machines to handle.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 228, 'prompt_tokens': 12, 'total_tokens': 240, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-81932894-e77e-441e-ae72-18d9617208e3-0', usage_metadata={'input_tokens': 12, 'output_tokens': 228, 'total_tokens': 240, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_no_parser = prompt_template | model\n",
    "chain_no_parser.invoke(\"Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying and Modifying Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a seasoned English teacher with 10 years of experience. Please write an English conversation suitable for the given situation.  \n",
    "Refer to the [FORMAT] for the structure.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- Dialogue in English:\n",
    "- Explanation of the Dialogue:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\" : \"I want to have my own house\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "Person A: I've been thinking about buying my own house lately.\n",
      "Person B: That's a great goal to have! Have you started looking at potential properties yet?\n",
      "\n",
      "- Explanation of the Dialogue:\n",
      "In this conversation, Person A expresses their desire to own a house. Person B responds positively and asks if Person A has started the process of looking at potential properties. This dialogue shows support and encouragement towards achieving the goal of owning a house.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

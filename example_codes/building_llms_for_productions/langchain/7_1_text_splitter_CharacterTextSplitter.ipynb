{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Text Splitter\n",
    "\n",
    "\n",
    "Việc tách văn bản (text splitting) là một bước quan trọng trong quá trình xử lý tài liệu với LangChain.\n",
    "\n",
    "`CharacterTextSplitter` cung cấp khả năng chia nhỏ văn bản (text chunking) hiệu quả, mang lại một số lợi ích chính:\n",
    "\n",
    "-   **Giới hạn Token (Token Limits):** Vượt qua các hạn chế về kích thước cửa sổ ngữ cảnh (context window size) của LLM.\n",
    "-   **Tối ưu hóa tìm kiếm (Search Optimization):** Cho phép truy xuất chính xác hơn ở cấp độ chunk.\n",
    "-   **Hiệu quả bộ nhớ (Memory Efficiency):** Xử lý tài liệu lớn một cách hiệu quả.\n",
    "-   **Duy trì ngữ cảnh (Context Preservation):** Duy trì tính mạch lạc của văn bản thông qua `chunk_overlap`.\n",
    "\n",
    "Hướng dẫn này khám phá việc triển khai thực tế của việc tách văn bản thông qua các phương pháp cốt lõi như `split_text()` và `create_documents()`, bao gồm các tính năng nâng cao như xử lý metadata.\n",
    "\n",
    "```bash\n",
    "pip install langchain_text_splitters\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CharacterTextSplitter Example\n",
    "\n",
    "Read and store contents from keywords file\n",
    "* Open `./data/appendix-keywords.txt` file and read its contents.\n",
    "* Store the read contents in the `file` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "   file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results.\n",
      "Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: Natural Language Processing, Search Algorithms, Data Mining\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words\n"
     ]
    }
   ],
   "source": [
    "print(file[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `CharacterTextSplitter` with parameters:\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "* `separator`: String to split text on (e.g., newlines, spaces, custom delimiters)\n",
    "* `chunk_size`: Maximum size of chunks to return\n",
    "* `chunk_overlap`: Overlap in characters between chunks\n",
    "* `length_function`: Function that measures the length of given chunks\n",
    "* `is_separator_regex`: Boolean indicating whether separator should be treated as a regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "   separator=\" \",           # Splits whenever a space is encountered in text\n",
    "   chunk_size=250,          # Each chunk contains maximum 250 characters\n",
    "   chunk_overlap=50,        # Two consecutive chunks share 50 characters\n",
    "   length_function=len,     # Counts total characters in each chunk\n",
    "   is_separator_regex=False # Uses space as literal separator, not as regex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results.\n",
      "Example: If a user searches for “planets in the solar system,” the'\n"
     ]
    }
   ],
   "source": [
    "# Create document objects from chunks and display the first one\n",
    "chunks = text_splitter.create_documents([file])\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrate metadata handling during document creation:\n",
    "\n",
    "* `create_documents` accepts both text data and metadata lists\n",
    "* Each chunk inherits metadata from its source document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results.\n",
      "Example: If a user searches for “planets in the solar system,” the' metadata={'document': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define metadata for each document\n",
    "metadatas = [\n",
    "   {\"document\": 1},\n",
    "   {\"document\": 2},\n",
    "]\n",
    "\n",
    "# Create documents with metadata\n",
    "documents = text_splitter.create_documents(\n",
    "   [file, file],  # List of texts to split\n",
    "   metadatas=metadatas,  # Corresponding metadata\n",
    ")\n",
    "\n",
    "print(documents[0])  # Display first document with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split text using the `split_text()` method.\n",
    "* `text_splitter.split_text(file)[0]` returns the first chunk of the split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Semantic Search\\n\\nDefinition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results.\\nExample: If a user searches for “planets in the solar system,” the'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the file text and return the first chunk\n",
    "text_splitter.split_text(file)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

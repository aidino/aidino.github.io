{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationEntityMemory\n",
    "\n",
    "`ConversationEntityMemory` cho phép hệ thống hội thoại giữ lại các sự kiện về các thực thể cụ thể được đề cập trong cuộc đối thoại.\n",
    "\n",
    "Nó trích xuất thông tin về các thực thể từ cuộc trò chuyện (sử dụng LLM) và tích lũy kiến thức về các thực thể này theo thời gian (cũng sử dụng LLM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Memory Conversation Example\n",
    "\n",
    "Ví dụ này minh họa cách sử dụng `ConversationEntityMemory` để lưu trữ và quản lý thông tin về các thực thể được đề cập trong một cuộc hội thoại. Cuộc hội thoại tích lũy kiến thức liên tục về các thực thể này trong khi vẫn duy trì luồng tự nhiên.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory.entity import ConversationEntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['entities', 'history', 'input'] input_types={} partial_variables={} template='\\nYou are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou assist with various tasks, from answering simple questions to providing detailed discussions on a wide range of topics. You can generate human-like text, allowing natural conversations and coherent, relevant responses.\\n\\nYou constantly learn and improve, processing large amounts of text to provide accurate and informative responses. You can use personalized information provided in the context below, along with your own generated knowledge.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "entity_memory_conversation_template = PromptTemplate(\n",
    "    input_variables=[\"entities\", \"history\", \"input\"],\n",
    "    template=\"\"\"\n",
    "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
    "\n",
    "You assist with various tasks, from answering simple questions to providing detailed discussions on a wide range of topics. You can generate human-like text, allowing natural conversations and coherent, relevant responses.\n",
    "\n",
    "You constantly learn and improve, processing large amounts of text to provide accurate and informative responses. You can use personalized information provided in the context below, along with your own generated knowledge.\n",
    "\n",
    "Context:\n",
    "{entities}\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Last line:\n",
    "Human: {input}\n",
    "You:\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "print(entity_memory_conversation_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_742366/4276868222.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationEntityMemory(llm=llm),\n",
      "/home/dino/miniconda3/envs/langchain/lib/python3.10/site-packages/pydantic/main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "/tmp/ipykernel_742366/4276868222.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=entity_memory_conversation_template,\n",
    "    memory=ConversationEntityMemory(llm=llm),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds like a wonderful initiative! Amelia's expertise in landscape photography combined with David's passion for wildlife conservation will surely create a unique and impactful gallery and learning center. By showcasing the beauty of nature through photography, they can raise awareness and support for conservation efforts. It's inspiring to see individuals using their talents to make a positive difference in the world.\n"
     ]
    }
   ],
   "source": [
    "# Input conversation\n",
    "response = conversation.predict(\n",
    "    input=(\n",
    "        \"Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders. \"\n",
    "        \"David is a wildlife conservationist dedicated to protecting endangered species. \"\n",
    "        \"They are planning to open a nature-inspired photography gallery and learning center that raises funds for conservation projects.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Print the assistant's response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Entity Memory\n",
    "Let's examine the conversation history stored in memory using the `memory.entity_store.store` method to verify memory retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amelia': 'Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders.',\n",
       " 'David': 'David is a wildlife conservationist dedicated to protecting endangered species.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the entity memory\n",
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More infomation\n",
    "\n",
    "**Khái niệm:**\n",
    "\n",
    "`ConversationEntityMemory` là một loại bộ nhớ trong LangChain được thiết kế để theo dõi và lưu trữ các thực thể (entities) quan trọng được đề cập trong cuộc trò chuyện. Các thực thể này có thể là tên người, địa điểm, tổ chức, hoặc bất kỳ đối tượng nào khác mà mô hình ngôn ngữ cho là quan trọng để duy trì ngữ cảnh của cuộc hội thoại.\n",
    "\n",
    "Không giống như các loại bộ nhớ đơn giản chỉ lưu trữ toàn bộ lịch sử trò chuyện, `ConversationEntityMemory` tập trung vào việc trích xuất và lưu trữ các thông tin cốt lõi về các thực thể này. Điều này giúp mô hình ngôn ngữ hiểu rõ hơn về những gì đã được thảo luận và đưa ra phản hồi chính xác hơn.\n",
    "\n",
    "**Ưu điểm:**\n",
    "\n",
    "* **Hiểu ngữ cảnh sâu sắc hơn:** Bằng cách theo dõi các thực thể, mô hình có thể duy trì ngữ cảnh tốt hơn, ngay cả khi cuộc trò chuyện kéo dài.\n",
    "* **Giảm thiểu thông tin thừa:** Chỉ lưu trữ các thực thể quan trọng giúp tiết kiệm tài nguyên và tăng hiệu quả xử lý.\n",
    "* **Phản hồi chính xác hơn:** Khả năng nhận biết và ghi nhớ các thực thể giúp mô hình đưa ra phản hồi phù hợp và chính xác hơn.\n",
    "\n",
    "**Hướng dẫn sử dụng:**\n",
    "\n",
    "1.  **Cài đặt:**\n",
    "    \n",
    "    ```bash\n",
    "    pip install langchain\n",
    "    ```\n",
    "    \n",
    "2.  **Khởi tạo:**\n",
    "    \n",
    "    ```python\n",
    "    from langchain.memory import ConversationEntityMemory\n",
    "    from langchain.llms import OpenAI\n",
    "    \n",
    "    llm = OpenAI(temperature=0)\n",
    "    memory = ConversationEntityMemory(llm=llm)\n",
    "    ```\n",
    "    \n",
    "3.  **Sử dụng trong chuỗi hội thoại:**\n",
    "    \n",
    "    ```python\n",
    "    memory.save_context({\"input\": \"Xin chào, tên tôi là An.\"}, {\"output\": \"Chào An!\"})\n",
    "    memory.save_context({\"input\": \"Tôi sống ở Hà Nội.\"}, {\"output\": \"Hà Nội là một thành phố tuyệt vời!\"})\n",
    "    \n",
    "    print(memory.load_memory_variables({}))\n",
    "    ```\n",
    "    \n",
    "    Trong ví dụ này:\n",
    "    \n",
    "    * `memory.save_context()` được sử dụng để lưu trữ các lượt hội thoại.\n",
    "    * `memory.load_memory_variables({})` được sử dụng để truy xuất các thực thể đã được lưu trữ.\n",
    "    \n",
    "\n",
    "**Ví dụ minh họa:**\n",
    "\n",
    "```python\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "\n",
    "template = \"\"\"Đây là cuộc hội thoại trước đó:\n",
    "{history}\n",
    "Bây giờ, hãy trả lời câu hỏi sau: {input}\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "print(conversation.predict(input=\"Tên của tôi là An.\"))\n",
    "print(conversation.predict(input=\"Tôi sống ở đâu?\"))\n",
    "```\n",
    "\n",
    "Trong ví dụ này:\n",
    "\n",
    "* `ConversationEntityMemory` giúp mô hình ghi nhớ tên \"An\" và địa điểm \"Hà Nội\".\n",
    "* Khi được hỏi \"Tôi sống ở đâu?\", mô hình có thể truy xuất thông tin từ bộ nhớ và trả lời chính xác.\n",
    "\n",
    "**Lưu ý:**\n",
    "\n",
    "* `ConversationEntityMemory` phụ thuộc vào khả năng trích xuất thực thể của mô hình ngôn ngữ.\n",
    "* Hiệu quả của nó có thể thay đổi tùy thuộc vào độ phức tạp của cuộc trò chuyện và chất lượng của mô hình ngôn ngữ.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

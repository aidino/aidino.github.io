{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Hub\n",
    "\n",
    "Đây là một ví dụ về việc truy xuất và thực thi các prompts từ LangChain Hub.\n",
    "LangChain Hub là một kho lưu trữ tập hợp các prompts thường được sử dụng trong nhiều dự án khác nhau. Điều này cho phép các developers tìm kiếm, truy xuất và thực thi các prompts này một cách hiệu quả bất cứ khi nào cần thiết, từ đó đơn giản hóa quy trình làm việc của họ.\n",
    "\n",
    "* **Tìm kiếm và phân loại Prompt:** Các developers có thể dễ dàng tìm thấy các prompts mong muốn bằng cách sử dụng tìm kiếm dựa trên từ khóa và phân loại.\n",
    "* **Khả năng tái sử dụng (Reusability):** Sau khi được tạo, một prompt có thể được tái sử dụng trong nhiều dự án, giảm thời gian phát triển.\n",
    "* **Thực thi theo thời gian thực (Real-time Execution):** Các prompts được truy xuất có thể được thực thi ngay lập tức thông qua LangChain để xem kết quả trong thời gian thực.\n",
    "* **Khả năng mở rộng và tùy chỉnh (Extensibility and Customization):** Ngoài các prompts mặc định được cung cấp, người dùng có thể linh hoạt thêm và sửa đổi các prompts theo nhu cầu của họ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dino\\miniconda3\\envs\\langchain\\lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: This is question \n",
      "Context: This is context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(context=\"This is context\", question=\"This is question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

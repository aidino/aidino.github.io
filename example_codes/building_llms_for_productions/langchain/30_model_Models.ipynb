{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Various LLM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI - GPT Series\n",
    "\n",
    "Các mô hình GPT của OpenAI là các mô hình ngôn ngữ dựa trên transformer tiên tiến được thiết kế cho các tác vụ như tạo văn bản, tóm tắt, dịch và Hỏi-Đáp (Q&A). Được cung cấp chủ yếu dưới dạng API dựa trên đám mây, chúng cho phép các nhà phát triển sử dụng các mô hình mà không cần phải lưu trữ chúng. Mặc dù không phải là mã nguồn mở (open-source), GPT cung cấp các mô hình được đào tạo trước (pre-trained) với khả năng tinh chỉnh (fine-tuning).\n",
    "\n",
    "### Các Biến Thể Mô Hình\n",
    "\n",
    "1.  **Dòng GPT-4o (Các Mô Hình Hàng Đầu)**\n",
    "    -   **GPT-4o**: Mô hình độ tin cậy cao với tốc độ được cải thiện so với Turbo\n",
    "    -   **GPT-4-turbo**: Mô hình mới nhất với khả năng vision, JSON và function calling\n",
    "    -   **GPT-4o-mini**: Mô hình cấp đầu vào vượt trội hiệu suất của GPT-3.5 Turbo\n",
    "\n",
    "2.  **Dòng O1 (Chuyên Gia Lý Luận)**\n",
    "    -   **O1**: Mô hình lý luận nâng cao cho giải quyết vấn đề phức tạp\n",
    "    -   **O1-mini**: Mô hình nhanh, tiết kiệm chi phí cho các tác vụ chuyên biệt\n",
    "\n",
    "3.  **Dòng GPT-4o Multimedia (Beta)**\n",
    "    -   **GPT-4o-realtime**: Mô hình xử lý âm thanh và văn bản thời gian thực\n",
    "    -   **GPT-4o-audio-preview**: Mô hình đầu vào/đầu ra âm thanh chuyên dụng\n",
    "\n",
    "### Tổng Quan về GPT-4o\n",
    "\n",
    "**Các Tính Năng Chính**\n",
    "-   Mô hình GPT-4 tiên tiến nhất với độ tin cậy nâng cao\n",
    "-   Xử lý nhanh hơn so với biến thể GPT-4-turbo\n",
    "-   Cửa sổ ngữ cảnh (context window) rộng lớn 128.000 token\n",
    "-   Dung lượng đầu ra tối đa 16.384 token\n",
    "\n",
    "**Hiệu Suất**\n",
    "-   Độ tin cậy và tính nhất quán vượt trội trong phản hồi\n",
    "-   Khả năng lý luận nâng cao trên nhiều tác vụ đa dạng\n",
    "-   Tốc độ tối ưu hóa cho các ứng dụng thời gian thực\n",
    "-   Hiệu quả cân bằng cho việc sử dụng tài nguyên\n",
    "\n",
    "**Trường Hợp Sử Dụng**\n",
    "-   Phân tích và giải quyết vấn đề phức tạp\n",
    "-   Tạo nội dung dạng dài (long-form)\n",
    "-   Tài liệu kỹ thuật chi tiết\n",
    "-   Tạo và đánh giá mã nâng cao (advanced code generation and review)\n",
    "\n",
    "**Thông Số Kỹ Thuật**\n",
    "-   Tối ưu hóa kiến trúc GPT mới nhất\n",
    "-   Độ chính xác phản hồi được cải thiện\n",
    "-   Các biện pháp an toàn tích hợp (built-in safety measures)\n",
    "-   Khả năng giữ ngữ cảnh nâng cao (enhanced context retention)\n",
    "\n",
    "Để biết thêm thông tin chi tiết, vui lòng tham khảo [tài liệu chính thức của OpenAI](https://platform.openai.com/docs/models#models-overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Llama Series\n",
    "\n",
    "Dòng Llama AI của Meta cung cấp các mô hình mã nguồn mở (open-source) cho phép tinh chỉnh (fine-tuning), chưng cất (distillation) và triển khai linh hoạt (flexible deployment).\n",
    "\n",
    "### Các Biến Thể Mô Hình\n",
    "\n",
    "1.  **Llama 3.1 (Đa Ngôn Ngữ)**\n",
    "    -   **8B**: Mô hình nhẹ, siêu nhanh cho thiết bị di động và thiết bị biên (edge devices)\n",
    "    -   **405B**: Mô hình nền tảng hàng đầu (flagship foundation model) cho nhiều trường hợp sử dụng đa dạng.\n",
    "\n",
    "2.  **Llama 3.2 (Nhẹ và Đa Phương Thức)**\n",
    "    -   **1B và 3B**: Các mô hình hiệu quả cho xử lý trên thiết bị (on-device processing)\n",
    "    -   **11B và 90B**: Các mô hình đa phương thức (multimodal models) với khả năng lý luận hình ảnh độ phân giải cao (high-resolution image reasoning).\n",
    "\n",
    "3.  **Llama 3.3 (Đa Ngôn Ngữ)**\n",
    "    -   **70B**: Hỗ trợ đa ngôn ngữ với hiệu suất nâng cao.\n",
    "\n",
    "### Tổng Quan về Llama 3.3\n",
    "\n",
    "**Tính Năng An Toàn**\n",
    "-   Kết hợp các kỹ thuật căn chỉnh (alignment techniques) để có phản hồi an toàn.\n",
    "\n",
    "**Hiệu Suất**\n",
    "-   So sánh được với các mô hình lớn hơn với ít tài nguyên hơn.\n",
    "\n",
    "**Hiệu Quả**\n",
    "-   Tối ưu hóa cho các GPU phổ biến, giảm nhu cầu về phần cứng.\n",
    "\n",
    "**Hỗ Trợ Ngôn Ngữ**\n",
    "-   Hỗ trợ tám ngôn ngữ, bao gồm tiếng Anh và tiếng Tây Ban Nha.\n",
    "\n",
    "**Đào Tạo**\n",
    "-   Được đào tạo trước (pre-trained) trên 15 nghìn tỷ token.\n",
    "-   Được tinh chỉnh (fine-tuned) thông qua Supervised Fine-tuning (SFT) và RLHF.\n",
    "\n",
    "    >   **Supervised Fine-tuning**: Supervised fine-tuning là quá trình cải thiện hiệu suất của mô hình AI hiện có bằng cách đào tạo nó với dữ liệu được gắn nhãn (labeled data). Ví dụ: nếu bạn muốn dạy mô hình tóm tắt văn bản, bạn cung cấp các cặp 'văn bản gốc' và 'văn bản tóm tắt' làm dữ liệu đào tạo. Thông qua quá trình đào tạo này với các cặp câu trả lời chính xác, mô hình có thể nâng cao hiệu suất của mình trên các tác vụ cụ thể.\n",
    "    >\n",
    "    >   **Reinforcement Learning with Human Feedback (RLHF)**: RLHF là một phương pháp mà các mô hình AI học cách tạo ra phản hồi tốt hơn thông qua phản hồi của con người. Khi AI tạo ra phản hồi, con người đánh giá chúng và mô hình được cải thiện dựa trên những đánh giá này. Giống như một học sinh cải thiện kỹ năng của mình thông qua phản hồi của giáo viên, AI phát triển để cung cấp các phản hồi có đạo đức và hữu ích hơn thông qua phản hồi của con người.\n",
    "\n",
    "**Trường Hợp Sử Dụng**\n",
    "\n",
    "Để biết thêm thông tin chi tiết, vui lòng tham khảo [tài liệu chính thức của Meta](https://www.llama.com/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic - Claude Series\n",
    "\n",
    "Các mô hình Claude của Anthropic là các mô hình ngôn ngữ tiên tiến với API dựa trên đám mây cho nhiều tác vụ NLP khác nhau. Các mô hình này cân bằng hiệu suất, tính an toàn và khả năng phản hồi thời gian thực.\n",
    "\n",
    "### Các biến thể mô hình\n",
    "\n",
    "1.  **Dòng Claude 3 (Các mô hình hàng đầu)**\n",
    "    * **Claude 3 Haiku**: Khả năng phản hồi gần như tức thì\n",
    "    * **Claude 3 Sonnet**: Trí tuệ và tốc độ cân bằng\n",
    "    * **Claude 3 Opus**: Hiệu suất mạnh mẽ cho các tác vụ phức tạp\n",
    "\n",
    "2.  **Dòng Claude 3.5 (Các mô hình nâng cao)**\n",
    "    * **Claude 3.5 Haiku**: Phản hồi thời gian thực nâng cao\n",
    "    * **Claude 3.5 Sonnet**: Khả năng nghiên cứu và phân tích tiên tiến\n",
    "\n",
    "### Tổng quan về Claude 3 Opus\n",
    "\n",
    "**Các tính năng cốt lõi**\n",
    "* Xử lý các tác vụ phức tạp cao như toán học và coding\n",
    "* Cửa sổ ngữ cảnh (context window) mở rộng để xử lý tài liệu chi tiết\n",
    "\n",
    "**Hiệu suất**\n",
    "* Độ tin cậy và tính nhất quán vượt trội\n",
    "* Tối ưu hóa cho các ứng dụng thời gian thực\n",
    "\n",
    "**Các trường hợp sử dụng**\n",
    "* Tạo nội dung dạng dài (long-form content generation)\n",
    "* Tài liệu kỹ thuật chi tiết (detailed technical documentation)\n",
    "* Tạo và đánh giá mã nâng cao (advanced code generation and review)\n",
    "\n",
    "Để biết thêm thông tin chi tiết, vui lòng tham khảo [tài liệu chính thức của Anthropic](https://docs.anthropic.com/en/docs/intro-to-claude).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google - Gemini\n",
    "\n",
    "Các mô hình Gemini của Google ưu tiên hiệu quả và khả năng mở rộng, được thiết kế cho một loạt các ứng dụng tiên tiến.\n",
    "\n",
    "### Các biến thể mô hình\n",
    "\n",
    "1.  **Gemini 1.5 Flash**: Cung cấp cửa sổ ngữ cảnh (context window) 1 triệu token\n",
    "2.  **Gemini 1.5 Pro**: Cung cấp cửa sổ ngữ cảnh (context window) 2 triệu token\n",
    "3.  **Gemini 2.0 Flash (Experimental)**: Mô hình thế hệ tiếp theo với tốc độ và hiệu suất nâng cao\n",
    "\n",
    "### Tổng quan về Gemini 2.0 Flash\n",
    "\n",
    "**Các tính năng cốt lõi**\n",
    "* Hỗ trợ API trực tiếp đa phương thức (multimodal live APIs) cho các ứng dụng truyền phát hình ảnh và âm thanh thời gian thực (real-time vision and audio streaming applications)\n",
    "* Khả năng hiểu không gian (spatial understanding) nâng cao và khả năng tạo hình ảnh gốc (native image generation capabilities)\n",
    "* Sử dụng công cụ tích hợp (integrated tool usage) và cải thiện các chức năng agent (improved agent functionalities)\n",
    "\n",
    "**Hiệu suất**\n",
    "* Cung cấp tốc độ nhanh hơn và hiệu suất được cải thiện so với các mô hình trước đó\n",
    "\n",
    "**Các trường hợp sử dụng**\n",
    "* Các ứng dụng truyền phát thời gian thực (real-time streaming applications)\n",
    "* Các tác vụ suy luận (reasoning tasks) để giải quyết vấn đề phức tạp\n",
    "* Tạo hình ảnh và văn bản (image and text generation)\n",
    "\n",
    "Để biết thêm thông tin chi tiết, hãy tham khảo [tài liệu Gemini của Google](https://ai.google.dev/gemini-api/docs/models/gemini).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral AI Models Overview\n",
    "\n",
    "Mistral AI cung cấp các mô hình thương mại và mã nguồn mở cho nhiều tác vụ NLP khác nhau, bao gồm các giải pháp chuyên dụng.\n",
    "\n",
    "### Các biến thể mô hình\n",
    "\n",
    "**Các mô hình thương mại**\n",
    "* Mistral Large 24.11: Đa ngôn ngữ với cửa sổ ngữ cảnh (context window) 128k\n",
    "* Codestral: Chuyên gia về coding với hỗ trợ hơn 80 ngôn ngữ\n",
    "* Dòng Ministral: Các mô hình gọn nhẹ cho các ứng dụng độ trễ thấp (low-latency applications)\n",
    "\n",
    "**Các mô hình mã nguồn mở**\n",
    "* Mathstral: Tập trung vào toán học (Mathematics-focused)\n",
    "* Codestral Mamba: Cửa sổ ngữ cảnh (context window) 256k cho các tác vụ coding\n",
    "\n",
    "Để biết thêm thông tin chi tiết, vui lòng tham khảo [tài liệu chính thức của Mistral](https://mistral.ai/technology/#models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alibaba - Qwen\n",
    "\n",
    "Các mô hình Qwen của Alibaba cung cấp các biến thể mã nguồn mở và thương mại được tối ưu hóa cho nhiều ngành và tác vụ khác nhau.\n",
    "\n",
    "### Các biến thể mô hình\n",
    "\n",
    "1.  **Qwen 2.5**: Mô hình đa ngôn ngữ tiên tiến\n",
    "2.  **Qwen-VL**: Khả năng đa phương thức (multimodal) văn bản và hình ảnh\n",
    "3.  **Qwen-Audio**: Chuyên về phiên âm và phân tích âm thanh\n",
    "4.  **Qwen-Coder**: Tối ưu hóa cho các tác vụ coding\n",
    "5.  **Qwen-Math**: Được thiết kế để giải quyết các bài toán toán học nâng cao\n",
    "\n",
    "### Các tính năng chính\n",
    "\n",
    "* Hiệu suất hàng đầu trên nhiều benchmark khác nhau\n",
    "* Triển khai dễ dàng với nền tảng Alibaba Cloud\n",
    "* Ứng dụng trong AI tạo sinh (generative AI), chẳng hạn như viết, tạo hình ảnh và phân tích âm thanh\n",
    "\n",
    "Để biết thêm thông tin chi tiết, hãy truy cập [trang Qwen chính thức của Alibaba Cloud](https://mistral.ai/technology/#models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

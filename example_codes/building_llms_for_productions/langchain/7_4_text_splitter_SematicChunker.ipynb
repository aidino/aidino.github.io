{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemanticChunker\n",
    "\n",
    "\n",
    "Hướng dẫn này đi sâu vào một Text Splitter sử dụng độ tương đồng ngữ nghĩa để tách văn bản.\n",
    "\n",
    "`SemanticChunker` của LangChain là một công cụ mạnh mẽ đưa việc chia chunk tài liệu lên một tầm cao mới. Không giống như các phương pháp truyền thống chia văn bản theo khoảng thời gian cố định, `SemanticChunker` phân tích ý nghĩa của nội dung để tạo ra các phân chia logic hơn.\n",
    "\n",
    "Phương pháp này dựa trên **mô hình embedding của OpenAI**, tính toán mức độ tương tự của các phần văn bản khác nhau bằng cách chuyển chúng thành biểu diễn số. Công cụ này cung cấp nhiều tùy chọn tách khác nhau để phù hợp với nhu cầu của bạn. Bạn có thể chọn từ các phương pháp dựa trên percentiles, độ lệch chuẩn hoặc khoảng tứ phân vị.\n",
    "\n",
    "Điều làm cho `SemanticChunker` khác biệt là khả năng bảo toàn ngữ cảnh bằng cách xác định các điểm ngắt tự nhiên. Điều này cuối cùng dẫn đến hiệu suất tốt hơn khi làm việc với các mô hình ngôn ngữ lớn.\n",
    "\n",
    "Vì `SemanticChunker` hiểu nội dung thực tế, nó tạo ra các chunk hữu ích hơn và duy trì luồng và ngữ cảnh của tài liệu gốc.\n",
    "\n",
    "Xem notebook của Greg Kamradt: [Greg Kamradt's notebook](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "\n",
    "```bash\n",
    "pip install langchain_experimental langchain_openai\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results.\n",
      "Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: \n"
     ]
    }
   ],
   "source": [
    "# Open the data/appendix-keywords.txt file to create a file object called f.\n",
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    file = f.read()  # Read the contents of the file and save it in the file variable.\n",
    "\n",
    "# Print part of the content read from the file.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a `SemanticChunker`\n",
    "\n",
    "The `SemanticChunker` is an experimental LangChain feature, that splits text into semantically similar chunks.\n",
    "\n",
    "This approach allows for more effective processing and analysis of text data.\n",
    "\n",
    "Use the `SemanticChunker` to divide the text into semantically related chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Initialize a semantic chunk splitter using OpenAI embeddings.\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitting\n",
    "\n",
    "Use the `text_splitter` with your loaded file (`file`) to split the text into smallar, more manageable unit documents. This process is often referred to as chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting, you can examine the resulting chunks to see how the text has been divided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results. Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: Natural Language Processing, Search Algorithms, Data Mining\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors. This allows computers to better understand and process the text.\n"
     ]
    }
   ],
   "source": [
    "# Print the first chunk among the divided chunks.\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_documents()` function allows you to convert the individual chunks ([`file`]) into proper document objects (`docs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results. Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: Natural Language Processing, Search Algorithms, Data Mining\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors. This allows computers to better understand and process the text.\n"
     ]
    }
   ],
   "source": [
    "# Split using text_splitter\n",
    "docs = text_splitter.create_documents([file])\n",
    "print(\n",
    "    docs[0].page_content\n",
    ")  # Print the content of the first document among the divided documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakpoints\n",
    "\n",
    "Quá trình chia chunk này hoạt động bằng cách xác định các điểm ngắt tự nhiên giữa các câu.\n",
    "\n",
    "Đây là cách nó quyết định vị trí tách văn bản:\n",
    "\n",
    "1.  Nó tính toán sự khác biệt giữa các embedding này cho mỗi cặp câu.\n",
    "2.  Khi sự khác biệt giữa hai câu vượt quá một ngưỡng nhất định (breakpoint), `text_splitter` xác định đây là điểm ngắt tự nhiên và tách văn bản tại điểm đó.\n",
    "\n",
    "Xem video của Greg Kamradt: [Greg Kamradt's video](https://youtu.be/8OJC21T2SL4?si=PzUtNGYJ_KULq3-w&t=2580) để biết thêm chi tiết.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentile-Based Splitting\n",
    "\n",
    "Phương pháp này sắp xếp tất cả các khác biệt embedding giữa các câu. Sau đó, nó tách văn bản tại một percentile cụ thể (ví dụ: percentile thứ 70).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # Initialize the semantic chunker using OpenAI's embedding model\n",
    "    OpenAIEmbeddings(),\n",
    "    # Set the split breakpoint type to percentile\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=70,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 0]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results. Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: Natural Language Processing, Search Algorithms, Data Mining\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors. This allows computers to better understand and process the text.\n",
      "============================================================\n",
      "[Chunk 1]\n",
      "\n",
      "Example: The word “apple” might be represented as a vector like [0.65, -0.23, 0.17]. Related Keywords: Natural Language Processing, Vectorization, Deep Learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token refers to a smaller unit of text obtained by splitting a larger text. It can be a word, sentence, or phrase.\n",
      "============================================================\n",
      "[Chunk 2]\n",
      "\n",
      "Example: The sentence “I go to school” can be split into tokens: “I”, “go”, “to”, “school”. Related Keywords: Tokenization, Natural Language Processing, Parsing\n",
      "\n",
      "Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is commonly used in natural language processing for data preprocessing.\n",
      "============================================================\n",
      "[Chunk 3]\n",
      "\n",
      "Example: The sentence “I love programming.” can be tokenized into [“I”, “love”, “programming”, “.”]. Related Keywords: Tokenization, Natural Language Processing, Parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system for storing data in vector form. It is used for tasks like retrieval, classification, and other data analysis.\n",
      "============================================================\n",
      "[Chunk 4]\n",
      "\n",
      "Example: Word embedding vectors can be stored in a database for quick access. Related Keywords: Embedding, Database, Vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL (Structured Query Language) is a programming language for managing data in databases. It supports operations like querying, modifying, inserting, and deleting data.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([file])\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(\n",
    "        doc.page_content\n",
    "    )  # Print the content of the first document among the split documents.\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `len(docs)` function to get the number of chunks created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))  # Print the length of docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation Splitting\n",
    "\n",
    "Phương pháp này đặt ngưỡng dựa trên một số lượng độ lệch chuẩn được chỉ định (`breakpoint_threshold_amount`).\n",
    "\n",
    "Để sử dụng độ lệch chuẩn cho điểm ngắt của bạn, hãy đặt tham số `breakpoint_threshold_type` thành `\"standard_deviation\"` khi khởi tạo `text_splitter`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # Initialize the semantic chunker using OpenAI's embedding model.\n",
    "    OpenAIEmbeddings(),\n",
    "    # Use standard deviation as the splitting criterion.\n",
    "    breakpoint_threshold_type=\"standard_deviation\",\n",
    "    breakpoint_threshold_amount=1.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting, check the `docs` list and print its length (`len(docs)`) to see how many chunks were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using text_splitter.\n",
    "docs = text_splitter.create_documents([file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 0]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results. Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: Natural Language Processing, Search Algorithms, Data Mining\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors. This allows computers to better understand and process the text.\n",
      "============================================================\n",
      "[Chunk 1]\n",
      "\n",
      "Example: The word “apple” might be represented as a vector like [0.65, -0.23, 0.17]. Related Keywords: Natural Language Processing, Vectorization, Deep Learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token refers to a smaller unit of text obtained by splitting a larger text. It can be a word, sentence, or phrase. Example: The sentence “I go to school” can be split into tokens: “I”, “go”, “to”, “school”. Related Keywords: Tokenization, Natural Language Processing, Parsing\n",
      "\n",
      "Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is commonly used in natural language processing for data preprocessing.\n",
      "============================================================\n",
      "[Chunk 2]\n",
      "\n",
      "Example: The sentence “I love programming.” can be tokenized into [“I”, “love”, “programming”, “.”]. Related Keywords: Tokenization, Natural Language Processing, Parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system for storing data in vector form. It is used for tasks like retrieval, classification, and other data analysis.\n",
      "============================================================\n",
      "[Chunk 3]\n",
      "\n",
      "Example: Word embedding vectors can be stored in a database for quick access. Related Keywords: Embedding, Database, Vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL (Structured Query Language) is a programming language for managing data in databases. It supports operations like querying, modifying, inserting, and deleting data.\n",
      "============================================================\n",
      "[Chunk 4]\n",
      "\n",
      "Example: SELECT * FROM users WHERE age > 18; retrieves information about users older than 18. Related Keywords: Database, Query, Data Management\n",
      "\n",
      "CSV\n",
      "\n",
      "Definition: CSV (Comma-Separated Values) is a file format for storing data where each value is separated by a comma. It is often used for simple data storage and exchange in tabular form.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([file])\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(\n",
    "        doc.page_content\n",
    "    )  # Print the content of the first document among the split documents.\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))  # Print the length of docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interquartile Range Splitting\n",
    "\n",
    "Phương pháp này sử dụng khoảng tứ phân vị (IQR) của các khác biệt embedding để xem xét các điểm ngắt, dẫn đến việc tách văn bản.\n",
    "\n",
    "Đặt tham số `breakpoint_threshold_type` thành `\"interquartile\"` khi khởi tạo `text_splitter` để sử dụng IQR cho việc tách.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # Initialize the semantic chunk splitter using OpenAI's embedding model.\n",
    "    OpenAIEmbeddings(),\n",
    "    # Set the breakpoint threshold type to interquartile range.\n",
    "    breakpoint_threshold_type=\"interquartile\",\n",
    "    breakpoint_threshold_amount=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 0]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching by understanding the meaning of the user’s query to return relevant results. Example: If a user searches for “planets in the solar system,” the system might return information about related planets such as “Jupiter” or “Mars.”\n",
      "Related Keywords: Natural Language Processing, Search Algorithms, Data Mining\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into low-dimensional continuous vectors. This allows computers to better understand and process the text.\n",
      "============================================================\n",
      "[Chunk 1]\n",
      "\n",
      "Example: The word “apple” might be represented as a vector like [0.65, -0.23, 0.17]. Related Keywords: Natural Language Processing, Vectorization, Deep Learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token refers to a smaller unit of text obtained by splitting a larger text. It can be a word, sentence, or phrase. Example: The sentence “I go to school” can be split into tokens: “I”, “go”, “to”, “school”. Related Keywords: Tokenization, Natural Language Processing, Parsing\n",
      "\n",
      "Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is commonly used in natural language processing for data preprocessing.\n",
      "============================================================\n",
      "[Chunk 2]\n",
      "\n",
      "Example: The sentence “I love programming.” can be tokenized into [“I”, “love”, “programming”, “.”]. Related Keywords: Tokenization, Natural Language Processing, Parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system for storing data in vector form. It is used for tasks like retrieval, classification, and other data analysis.\n",
      "============================================================\n",
      "[Chunk 3]\n",
      "\n",
      "Example: Word embedding vectors can be stored in a database for quick access. Related Keywords: Embedding, Database, Vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL (Structured Query Language) is a programming language for managing data in databases. It supports operations like querying, modifying, inserting, and deleting data.\n",
      "============================================================\n",
      "[Chunk 4]\n",
      "\n",
      "Example: SELECT * FROM users WHERE age > 18; retrieves information about users older than 18. Related Keywords: Database, Query, Data Management\n",
      "\n",
      "CSV\n",
      "\n",
      "Definition: CSV (Comma-Separated Values) is a file format for storing data where each value is separated by a comma. It is often used for simple data storage and exchange in tabular form.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Split using text_splitter.\n",
    "docs = text_splitter.create_documents([file])\n",
    "\n",
    "# Print the results.\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(\n",
    "        doc.page_content\n",
    "    )  # Print the content of the first document among the split documents.\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))  # Print the length of docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x74a5c8191ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding how gating works\n",
    "num_experts = 4\n",
    "top_k = 2\n",
    "n_embed=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake multihead attention output\n",
    "mh_output = torch.randn(2, 4, n_embed) # (B, T, C) = (2, 4, 32) = (batch_size, block_size, n_embed)\n",
    "mh_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topkgate_linear = nn.Linear(n_embed, num_experts)\n",
    "logits = topkgate_linear(mh_output)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5094,  0.1819,  1.4175, -1.2313],\n",
       "         [-0.6516, -0.3523,  0.2325, -0.1282],\n",
       "         [-0.5160,  0.4784,  0.5277,  0.0849],\n",
       "         [-0.1585,  0.7327, -0.0731,  1.1971]],\n",
       "\n",
       "        [[-1.0861, -0.4558,  0.8626, -0.2610],\n",
       "         [ 0.4096, -1.2683,  0.1333, -0.7036],\n",
       "         [-1.1600,  0.6790,  1.1870, -0.0982],\n",
       "         [-0.5390,  0.4700, -0.0688,  0.9904]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy top_k giá trị lớn nhất và chỉ số của chúng từ logits theo chiều cuối cùng (dim=-1).\n",
    "top_k_logit, top_k_idx = logits.topk(top_k, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4175,  0.5094],\n",
       "         [ 0.2325, -0.1282],\n",
       "         [ 0.5277,  0.4784],\n",
       "         [ 1.1971,  0.7327]],\n",
       "\n",
       "        [[ 0.8626, -0.2610],\n",
       "         [ 0.4096,  0.1333],\n",
       "         [ 1.1870,  0.6790],\n",
       "         [ 0.9904,  0.4700]]], grad_fn=<TopkBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 0],\n",
       "         [2, 3],\n",
       "         [2, 1],\n",
       "         [3, 1]],\n",
       "\n",
       "        [[2, 3],\n",
       "         [0, 2],\n",
       "         [2, 1],\n",
       "         [3, 1]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lấy đầu ra sparse gating bằng cách chỉ giữ lại k giá trị hàng đầu tại chỉ số tương ứng của chúng dọc theo chiều cuối cùng. Điền phần còn lại bằng ‘-inf’ và truyền qua hàm kích hoạt softmax. Điều này đẩy các giá trị ‘-inf’ về không, làm cho hai giá trị hàng đầu được nhấn mạnh hơn và tổng bằng 1. Tổng bằng 1 này giúp ích cho việc tính trọng số của đầu ra expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-inf, -inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "        [[-inf, -inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf, -inf],\n",
       "         [-inf, -inf, -inf, -inf]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo một tensor zeros có cùng shape với logits (tức (2, 4, num_experts)).\n",
    "# Các phần tử được điền giá trị âm vô cực (-inf).\n",
    "# Mục đích là để tạo một mask mà chỉ giữ lại các giá trị top-k.\n",
    "zeros = torch.full_like(logits, float('-inf'))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5094,    -inf,  1.4175,    -inf],\n",
       "         [   -inf,    -inf,  0.2325, -0.1282],\n",
       "         [   -inf,  0.4784,  0.5277,    -inf],\n",
       "         [   -inf,  0.7327,    -inf,  1.1971]],\n",
       "\n",
       "        [[   -inf,    -inf,  0.8626, -0.2610],\n",
       "         [ 0.4096,    -inf,  0.1333,    -inf],\n",
       "         [   -inf,  0.6790,  1.1870,    -inf],\n",
       "         [   -inf,  0.4700,    -inf,  0.9904]]], grad_fn=<ScatterBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo tensor thưa bằng cách đặt các giá trị top_k_logit vào vị trí được chỉ định bởi top_k_idx.\n",
    "# scatter thay thế các giá trị -inf tại các chỉ số top_k_idx bằng top_k_logit.\n",
    "# Kết quả sparse_logits có shape (2, 4, num_experts), trong đó:\n",
    "# Chỉ có top_k giá trị khác -inf ở mỗi chuỗi\n",
    "# Các vị trí khác vẫn là -inf\n",
    "sparse_logits = zeros.scatter(-1, top_k_idx, top_k_logit)\n",
    "sparse_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2874, 0.0000, 0.7126, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5892, 0.4108],\n",
       "         [0.0000, 0.4877, 0.5123, 0.0000],\n",
       "         [0.0000, 0.3860, 0.0000, 0.6140]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.7547, 0.2453],\n",
       "         [0.5686, 0.0000, 0.4314, 0.0000],\n",
       "         [0.0000, 0.3757, 0.6243, 0.0000],\n",
       "         [0.0000, 0.3728, 0.0000, 0.6272]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gating_output= F.softmax(sparse_logits, dim=-1)\n",
    "gating_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nếu chỉ dùng top-k sẽ rất có khả năng có những expert được chọn nhiều lần, điều đó dẫn đến không cân bằng tải.\n",
    "\n",
    "=> Phương pháp: Noisy top-k Gating for load balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the top k router module \n",
    "class TopkRouter(nn.Module):\n",
    "    def __init__(self, n_embed, num_experts, top_k):\n",
    "        super(TopkRouter, self).__init__()\n",
    "        self.top_k = top_k\n",
    "        self.linear =nn.Linear(n_embed, num_experts)\n",
    "    \n",
    "    def forward(self, mh_ouput):\n",
    "        # mh_ouput is the output tensor from multihead self attention block\n",
    "        logits = self.linear(mh_output)\n",
    "        top_k_logits, indices = logits.topk(self.top_k, dim=-1)\n",
    "        zeros = torch.full_like(logits, float('-inf'))\n",
    "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)\n",
    "        router_output = F.softmax(sparse_logits, dim=-1)\n",
    "        return router_output, indices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
